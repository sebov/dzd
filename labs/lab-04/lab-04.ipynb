{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61d579f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab 04 - Similarity Search in Large Datasets - LSH with Shingling, MinHashing and Banding\n",
    "\n",
    "During this lab we will continue our study of Similarity Search in large datasets. This time, we\n",
    "will implement Locality-Sensitive Hashing (LSH) using Shingling, MinHashing, and Banding techniques\n",
    "to find similar text documents.\n",
    "\n",
    "Get familiar with the concepts of Shingling, MinHashing, and Banding by reviewing the relevant\n",
    "materials from Chapter 3 of \"Mining of Massive Datasets\" - http://www.mmds.org/ -\n",
    "[pdf](http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07679e3e",
   "metadata": {},
   "source": [
    "## 1. The Dataset\n",
    "\n",
    "For preliminary experiments, we will use a smaller text dataset\n",
    "[sentence-transformers/stsb](https://huggingface.co/datasets/sentence-transformers/stsb) hosted on\n",
    "Hugging Face Datasets. Download it manually or use the `datasets` library (the suggested way) to\n",
    "load it into your notebook. You can merge sentences from the \"sentence1\" and \"sentence2\" features\n",
    "to make the dataset larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8900444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0110f",
   "metadata": {},
   "source": [
    "## 2. Investigate the Dataset\n",
    "\n",
    "Explore the dataset to understand its content. What kind of text documents does it contain? How many\n",
    "documents are there after merging all splits? What is the minimum, maximum, and average length of\n",
    "the documents? Is it easy to find similar documents in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45020d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eac6212",
   "metadata": {},
   "source": [
    "## 3. Lab Preliminaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3cc0ba",
   "metadata": {},
   "source": [
    "### 3.1 Shingling\n",
    "\n",
    "Shingling is the process of producing a list or set of contiguous subsequences (shingles) from a\n",
    "document. Shingles can consist of a predefined number of characters or words.\n",
    "\n",
    "E.g., for the sentence \"To be or not to be, that is the question\":\n",
    "- character 3-shingles: \"To \", \"o b\", \" be\", \"be \", \"e o\", ...\n",
    "- word 2-shingles: \"To be\", \"be or\", \"or not\", \"not to\", ...\n",
    "\n",
    "Shingles can be represented as strings (as above) or tuples of characters/words. There are also\n",
    "multiple valid ways to handle spaces, punctuation, capitalization, stop words, etc. The choice \n",
    "depends on the application.\n",
    "\n",
    "Prepare a modular and extensible implementation of shingling that allows you to easily change the\n",
    "way shingles are created. This includes different shingle types (character-based, word-based), the\n",
    "length of shingles, the result format (set or list), and different pre-processing options for\n",
    "handling spaces and punctuation, capitalization, stop words, etc. You can split the the process into\n",
    "two steps - tokenization and shingle creation, but other approaches are also acceptable. Be\n",
    "creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b82cc",
   "metadata": {},
   "source": [
    "### 3.2 MinHashing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e2965",
   "metadata": {},
   "source": [
    "### 3.3 Banding and Locality-Sensitive Hashing (LSH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41364e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6077407",
   "metadata": {},
   "source": [
    "## 4. Approximate Nearest Neighbors Search with LSH for Text Documents\n",
    "\n",
    "Using your implementations from the previous section, build an approximate nearest neighbors search\n",
    "system based on LSH for the text documents in your dataset. Experiment with different parameters for\n",
    "shingling, MinHashing, and banding and try to visually inspect whether the returned results are \n",
    "reasonable.\n",
    "\n",
    "How do different parameter choices affect the size of internal structures (e.g., actual number of\n",
    "shingles, the size of hash tables, etc.), as well as the preprocessing, indexing and query times.\n",
    "Plot graphs to illustrate your findings.\n",
    "\n",
    "In the original dataset, there are \"sentence1\" and \"sentence2\" pairs and their similarity scores.\n",
    "Can you propose an experimental setup to quantitatively evaluate (at least partially) your\n",
    "implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4553da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b1486",
   "metadata": {},
   "source": [
    "## 5. Large Dataset\n",
    "\n",
    "Is your implementation efficient and scalable enough to handle a larger dataset? Try to run it on a\n",
    "larger text dataset, e.g.,\n",
    "[sentence-transformers/gooaq](https://huggingface.co/datasets/sentence-transformers/gooaq),\n",
    "[sentence-transformers/amazon-qa](https://huggingface.co/datasets/sentence-transformers/amazon-qa),\n",
    "[sentence-transformers/amazon-reviews](https://huggingface.co/datasets/sentence-transformers/amazon-reviews).\n",
    "\n",
    "What is the maximum dataset subset size your implementation can handle on your machine? How much time\n",
    "is needed to preprocess, index, and query the dataset?\n",
    "\n",
    "The solutions presented in Section 3 are considered to be baseline approaches. Can you think of any\n",
    "optimizations or improvements to make your implementation more efficient and scalable? For larger\n",
    "datasets or higher parameter shingling lengths it may be necessary to avoid storing the entire set\n",
    "of shingles or generating actual permutations for MinHashing in memory. Can you propose any\n",
    "space-efficient improvements or heuristics to speed up the computations and reduce memory usage?\n",
    "\n",
    "Perform experiments to evaluate the time and memory requirements of your implementation. Plot graphs\n",
    "to illustrate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4aad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
