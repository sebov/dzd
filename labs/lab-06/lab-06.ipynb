{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61d579f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab 06 - Scalable Computations with the MapReduce Framework - Processing Large Datasets\n",
    "\n",
    "During this lab we will implement an algorithm that uses the MapReduce framework to process large\n",
    "datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089745b8",
   "metadata": {},
   "source": [
    "## 1. The Dataset\n",
    "\n",
    "We are going to use a dataset from our previous labs - [NYC Yellow Taxi Trip\n",
    "Data](https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data) from Kaggle - which is a\n",
    "subset of the original dataset provided by the [NYC Taxi & Limousine Commission\n",
    "(TLC)](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5267f2",
   "metadata": {},
   "source": [
    "## 2. Preprocess the Dataset\n",
    "\n",
    "Clean and preprocess the dataset - handle missing values, engineer new features (e.g., a day of the\n",
    "week from time-related columns), perform discretization if needed, etc.\n",
    "\n",
    "Ideally, you should perform the computations using combinations or pipelines of MapReduce jobs/steps\n",
    "(when processing the entire dataset) and plain Python/Pandas/NumPy (when working with smaller\n",
    "intermediate result from MapReduce). For example, you could perform min-max normalization by\n",
    "computing the minimum and maximum values for each column in one MapReduce job/step, and then use\n",
    "these values to normalize the data in a separate step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d89c03",
   "metadata": {},
   "source": [
    "## 3. Implement Clustering Algorithm\n",
    "\n",
    "Implement an algorithm from the family of k-means, k-modes, or k-prototypes, depending on the types\n",
    "of features you have engineered. Remember that the data should be properly preprocessed before\n",
    "applying an algorithm of your choice, e.g., what is the risk of using k-means on features with very\n",
    "different scales? Use hyperparameters such as the number of clusters `k`, the distance measure, the\n",
    "maximum number of iterations, etc.\n",
    "\n",
    "Similarly to the previous section, you should perform computations using combinations or pipelines\n",
    "of MapReduce jobs/steps and plain Python/Pandas/NumPy. Prepare your solution so that it is easy to \n",
    "run with different values of hyperparameters (e.g., `k`).\n",
    "\n",
    "Experiment with different hyperparameters and paralellization settings (either using mrjob inline\n",
    "or local modes, or by using an actual Hadoop cluster).\n",
    "\n",
    "Compare the results and computation times with those obtained in the previous lab for this\n",
    "dataset and task. Are the times significantly different? If so, why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
