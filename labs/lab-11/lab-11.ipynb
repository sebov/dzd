{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41db0b5d",
   "metadata": {},
   "source": [
    "# Lab 11 - Association Rule Learning - Apriori Algorithm\n",
    "\n",
    "During this lab we will explore association rule learning. It is a domain of data mining that\n",
    "focuses on discovering interesting relationships between variables in transactional data. You will\n",
    "familiarize yourself with basic concepts such as association rules, support, confidence, lift, and\n",
    "leverage and you will implement the Apriori algorithm.\n",
    "\n",
    "You can also deepen your understanding and knowledge by studying the relevant materials from\n",
    "[Chapter 6 (pdf)](http://infolab.stanford.edu/~ullman/mmds/ch6.pdf) of \"Mining of Massive Datasets\"\n",
    "\\- http://www.mmds.org/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bdf68",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "One of the most popular types of datasets for association rule learning is the market basket. For\n",
    "this lab we have several datasets available (they will be described in the next subsections). Try to\n",
    "familiarize yourself with the datasets and choose the one that you find most interesting and that\n",
    "matches the resources available to you.\n",
    "\n",
    "---\n",
    "\n",
    "Preprocess the dataset into a format that is appropriate for checking the co-occurrences of products\n",
    "in transactions. It is up to you to decide what that format should be in order to perform the\n",
    "computations efficiently. You will later need to answer questions such as \"What is the overall\n",
    "number of transactions?\", \"What is the number of transactions in which a specific product was\n",
    "bought?\", \"What is the number of transactions in which two specific products were bought?\", etc. You\n",
    "may start with the original data layout and then return to this step if needed.\n",
    "\n",
    "---\n",
    "\n",
    "Find top 10 products that customers bought the most and least often.\n",
    "\n",
    "---\n",
    "\n",
    "You may think of limiting the number of products to consider - for example, is there a point in\n",
    "considering products that were bought less than 10 times? 100? 1000? That definitely depends on the\n",
    "particular dataset and context. It is up to you to decide what makes sense for your analysis.\n",
    "Justify your choice.\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:gold\">Note:</span> The dataset may suggest that the \"in\" relationship between\n",
    "items and baskets corresponds to real-life \"part of\" relationship. This is true in this case:\n",
    "products (items) are purchased together in larger transactions (baskets). However, you should be\n",
    "aware that for association rule learning, the \"in\" relationship could be any arbitrary many-to-many\n",
    "relationship, even if it appears \"backwards\" compared to real life. See [Section 6.1.2\n",
    "(pdf)](http://infolab.stanford.edu/~ullman/mmds/ch6.pdf) for an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1bafb",
   "metadata": {},
   "source": [
    "### 1.1 Instacart Online Grocery Shopping\n",
    "\n",
    "A dataset that represents transactions of customers from the Instacart online grocery delivery\n",
    "platform. The \"The Instacart Online Grocery Shopping Dataset 2017\" was provided on the Kaggle\n",
    "platform. Although it is not available at its original location, you can find the files at:\n",
    "- https://www.kaggle.com/datasets/yasserh/instacart-online-grocery-basket-analysis-dataset\n",
    "- or \n",
    "- https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis\n",
    "- or \n",
    "- https://www.kaggle.com/datasets/suhasyogeshwara/instcart-market-analysis\n",
    "\n",
    "It is a classic example of a market basket analysis dataset. Download the dataset, extract the files\n",
    "and familiarize yourself with the data.\n",
    "\n",
    "There are 6 files available:\n",
    "- `aisles.csv` - aisles of the store\n",
    "- `departments.csv` - departments of the store\n",
    "- `order_products__prior.csv` - details of prior orders (historical data), tells which items\n",
    "  (products) were bought together in one basket (transaction)\n",
    "- `order_products__train.csv` - details of train orders (last order for each customer)\n",
    "- `orders.csv` - orders of the customers\n",
    "- `products.csv` - products of the store\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We are not going to use the whole information provided by the dataset. For now, we are interested in\n",
    "the list of products that customers bought in each transaction. Let's focus on the\n",
    "`order_products__prior.csv` (historical transactions data) and `products.csv` (for the names of the\n",
    "products) files.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    ">>> order_products_prior_df[order_products_prior_df[\"order_id\"] == 2]\n",
    "\n",
    "    order_id  product_id  add_to_cart_order  reordered\n",
    "59         7       34050                  1          0\n",
    "60         7       46802                  2          0\n",
    "```\n",
    "\n",
    "We can see that a customer bought two products (with id `34050` and `46802`) in one transaction. \n",
    "\n",
    "If we want to check the names of the products, we can use the `products.csv` file:\n",
    "\n",
    "```python\n",
    ">>> products_df[products_df[\"product_id\"].isin([34050, 46802])]\n",
    "\n",
    "       product_id      product_name  aisle_id  department_id\n",
    "34049       34050      Orange Juice        31              7\n",
    "46801       46802  Pineapple Chunks       116              1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62087f58",
   "metadata": {},
   "source": [
    "### 1.2 Online Retail / Online Retail II\n",
    "\n",
    "Use Online Retail or Online Retail II dataset from UCI Machine Learning Repository. These datasets\n",
    "represent transactions of a UK-based online retail store that focuses on selling unique all-occasion\n",
    "gifts.\n",
    "\n",
    "The datasets are provided as XLSX files. Note that Online Retail II contains two separate sheets for\n",
    "two consecutive years of transactions (you may consider merging them into a single dataframe).\n",
    "\n",
    "- https://archive.ics.uci.edu/dataset/352/online+retail\n",
    "- https://archive.ics.uci.edu/dataset/502/online+retail+ii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98defd",
   "metadata": {},
   "source": [
    "## 2. Association Rules\n",
    "\n",
    "Association rules are rules that express the relationship between items in transactions. They are\n",
    "usually presentented in the form `A -> B`, where `A` and `B` are subsets of items, and `A -> B`\n",
    "means that if items from `A` are purchased, then items from `B` are also purchased. We will refer to\n",
    "`A` as the antecedent and `B` as the consequent of the rule. It is quite common to consider\n",
    "consequents as single items, as it is easier to interpret the rules. For example, if the client buys\n",
    "bread and milk, then what other item is likely to be purchased with them?\n",
    "\n",
    "Let's consider an association rule `A -> B`.There are several metrics that can be used to evaluate\n",
    "its quality.  The most common metrics are:\n",
    "- `support` - the ratio of transactions that contain items from both `A` and `B` to the total number\n",
    "  of transactions (alternatively, just the number of such transactions); we can interpret it as how\n",
    "  often the rule applies,\n",
    "- `confidence` - the ratio of transactions that contain both `A` and `B` to the number of\n",
    "  transactions that contain `A`; we can interpret it as the probability of purchasing `B` given that\n",
    "  `A` was purchased,\n",
    "- `coverage` - the ratio of transactions that contain items from `A` to the total number of\n",
    "  transactions; we can interpret it as how often is `A` purchased; it informs us about the general\n",
    "  popularity of items from `A` in transactions and what is the fraction of transactions that the\n",
    "  rule is under consideration (no matter if `B` is purchased or not).\n",
    "  \n",
    "<span style=\"color:gold\">Note:</span> The concept of coverage can be defined not only\n",
    "for rules but also for itemsets. It is the ratio of transactions that contain the items from the\n",
    "itemset to the total number of transactions.\n",
    "\n",
    "---\n",
    "\n",
    "Write functions that let you compute support, confidence, and coverage metrics for association\n",
    "rules. It is up to you to define the expected association rule structure, e.g., a dictionary, a\n",
    "tuple, a named tuple, a dataclass, etc.\n",
    "\n",
    "Below, the product names are used for simplicity, but you should adapt this to the format you\n",
    "decided on in the previous step. Use your functions to compute the support, confidence, and coverage\n",
    "metrics of the following association rules:\n",
    "- {Bread} -> {Milk}\n",
    "- {Milk} -> {Bread}\n",
    "- {Bread, Milk} -> {Butter}\n",
    "- {Banana, Apple} -> {Milk}\n",
    "- {Bread, Milk, Butter} -> {Eggs}\n",
    "\n",
    "The example items above should work for the \"Instacart\" dataset. For the \"Online Retail\" dataset,\n",
    "please choose your own appropriate example products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa48f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062138a2",
   "metadata": {},
   "source": [
    "## 3. Apriori Algorithm\n",
    "\n",
    "Before we start with the details on how to efficiently search for association rules, let's first\n",
    "state that the number of possible association rules is exponential in the number of items. We can\n",
    "choose any item as the consequent and any subset of the items as the antecedent. However, most of\n",
    "these association rules are not interesting and have no practical value. What we usually want to\n",
    "find (at least in the most basic cases) are association rules that have large enough support and\n",
    "confidence.\n",
    "\n",
    "To find an useful association rule is not much different from finding an interesting/frequent\n",
    "itemset. It is said that for brick-and-mortar stores, the reasonable threshold could be around 1%\n",
    "of the transactions. For online stores, where the number of products is much larger, the threshold\n",
    "is usually even lower ~0.1%.\n",
    "\n",
    "In practice, we strive to obtain not too many frequent itemsets and association rules. The computed\n",
    "results are usually presented to or interpreted by a human. Each additional association rule\n",
    "candidate needs some action to be taken. It is quite normal to modify the thresholds for support\n",
    "and confidence to modify the number of association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cc999",
   "metadata": {},
   "source": [
    "### 3.1 Frequent Itemsets\n",
    "\n",
    "Frequent itemsets are the sets of items that appear together in a transaction with a frequency\n",
    "higher than a given threshold. In other words, we are interested in itemsets with \"high\" (that\n",
    "depends on the context) coverage.\n",
    "\n",
    "**Monotonicity Property**: If `A` is a frequent itemset, then all subsets of `A` are frequent\n",
    "itemsets.\n",
    "\n",
    "Can you prove this property?\n",
    "\n",
    "---\n",
    "\n",
    "Below, the product names are used for simplicity, but you should adapt this to the format you\n",
    "decided on in the previous step. Compute the frequency of the following itemsets:\n",
    "- {Bread}\n",
    "- {Milk}\n",
    "- {Banana}\n",
    "- {Bread, Milk}\n",
    "- {Bread, Butter}\n",
    "- {Bread, Milk, Butter, Banana}\n",
    "\n",
    "How would you choose a reasonable frequency threshold to use? How would you approach this problem?\n",
    "What are the trade-offs?\n",
    "\n",
    "The example items above should work for the \"Instacart\" dataset. For the \"Online Retail\" dataset,\n",
    "please choose your own appropriate example products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a60aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a56c44",
   "metadata": {},
   "source": [
    "### 3.2 Searching for Frequent Itemsets\n",
    "\n",
    "As a consequence of the above property, if we detect an itemset that is not frequent, then we know\n",
    "that all its supersets are not frequent either. That observation is the basis of the Apriori\n",
    "algorithm.\n",
    "\n",
    "Apriori algorithm was first proposed by R. Agrawal et al. in 1994 \"Fast Algorithms for Mining\n",
    "Association Rules\" [pdf](https://www.vldb.org/conf/1994/P487.PDF). It is an iterative algorithm\n",
    "for discovering frequent itemsets in a transaction database. The monotonicity property is used to\n",
    "prune the search space. Given a desired support threshold `s`, the algorithm can be described by the\n",
    "following steps (see the link above for more details):\n",
    "\n",
    "\n",
    "- compute the set $L_1$ of all frequent $1$-itemsets\n",
    "- generate all pairs of distinct $1$-itemsets from $L_1$ and take their union to form the candidate\n",
    "  set $C_2$ of $2$-itemsets\n",
    "- filter out the itemsets from $C_2$ if their support is lower than `s`; this results in the set\n",
    "  $L_2$ of true frequent $2$-itemsets\n",
    "- we can generalize this process as follows:\n",
    "    - assume that the set $L_{k-1}$ has been already computed\n",
    "    - generate all pairs of distinct frequent $(k-1)$-itemsets from $L_{k-1}$ that differ by exactly\n",
    "      one element; for each such pair, take their union to obtain an itemset `X` of size $k$; if all\n",
    "      subsets of `X` of size $(k-1)$ are frequent, add `X` to the candidate set $C_k$\n",
    "    - filter out the itemsets from $C_k$ if their support is lower than `s`; this results in the set\n",
    "      $L_k$ of true frequent $k$-itemsets\n",
    "- the process stops when $L_k$ becomes empty or when the maximum itemset length to consider has been\n",
    "  reached\n",
    "\n",
    "Implement the Apriori algorithm and apply it to the dataset. Keep in mind that, depending on the\n",
    "chosen parameters, the number of generated itemsets may become very large. Our goal is to identify\n",
    "the interesting itemsets without being overwhelmed by an excessive number of them. Therefore, begin\n",
    "with relatively high support thresholds and gradually lower them to discover additional itemsets.\n",
    "Adjust thresholds based on the available computational, memory or time resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1729556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c005f",
   "metadata": {},
   "source": [
    "### 3.3 Association Rules Generation\n",
    "\n",
    "Suppose we have identified all \"interesting\" itemsets. We can then generate interesting association\n",
    "rules (meeting some additional criteria, such as \"high\" confidence) from them. The procedure to\n",
    "generate association rules from a frequent itemset `A` can be as simple as follows:\n",
    "- `A` consists of `n` items,\n",
    "- we have `n` possible association rules of the form $A \\setminus \\{a\\} \\rightarrow \\{a\\}$ for each\n",
    "  item $a \\in A$,\n",
    "- we check the confidence of each rule and keep only the ones that meet the confidence threshold.\n",
    "\n",
    "Prepare a function that for a given itemset `A` and a confidence threshold generates association\n",
    "rules that meet the confidence threshold.\n",
    "\n",
    "Generate the set of association rules from the frequent itemsets found in the previous step. Compute\n",
    "statistics (support, confidence) for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f20b4",
   "metadata": {},
   "source": [
    "### 3.4 Compare the Results\n",
    "\n",
    "Compare the results you have obtained with the results from any of the available libraries. To\n",
    "mention a few:\n",
    "- https://rasbt.github.io/mlxtend/\n",
    "- https://github.com/tommyod/Efficient-Apriori\n",
    "\n",
    "Are the results the same or sufficiently close? Are the run times required to run your code\n",
    "comparable to those of the libraries?\n",
    "\n",
    "<span style=\"color:gold\">Note:</span> You may want to use some features of the libraries to make it\n",
    "possible to run the computations on the entire dataset. For example, consider using the\n",
    "`min_support` (start with higher required support and then lower it), `max_len` (start with smaller\n",
    "max_len and then increase it), `low_memory` parameters in the `mlxtend` library or transform the\n",
    "entire dataset into a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2304d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
