{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41db0b5d",
   "metadata": {},
   "source": [
    "# Lab 11 - Association Rule Learning - Apriori Algorithm\n",
    "\n",
    "During this lab we will explore association rule learning. It is a domain of data mining that\n",
    "focuses on discovering interesting relationships between variables in transactional data. You will\n",
    "familiarize yourself with basic concepts such as association rules, support, confidence, lift, and\n",
    "leverage and you will implement the Apriori algorithm.\n",
    "\n",
    "You can also deepen your understanding and knowledge by studying the relevant materials from\n",
    "[Chapter 6 (pdf)](http://infolab.stanford.edu/~ullman/mmds/ch6.pdf) of \"Mining of Massive Datasets\"\n",
    "\\- http://www.mmds.org/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9bdf68",
   "metadata": {},
   "source": [
    "## 1. The Dataset\n",
    "\n",
    "We will use a dataset that represents transactions of customers from the Instacart online grocery\n",
    "delivery platform. The \"The Instacart Online Grocery Shopping Dataset 2017\" was provided on the\n",
    "Kaggle platform. Although it is not available at its original location, you can find the files at:\n",
    "- https://www.kaggle.com/datasets/yasserh/instacart-online-grocery-basket-analysis-dataset\n",
    "- or \n",
    "- https://www.kaggle.com/datasets/psparks/instacart-market-basket-analysis\n",
    "- or \n",
    "- https://www.kaggle.com/datasets/suhasyogeshwara/instcart-market-analysis\n",
    "\n",
    "It is a classic example of a market basket analysis dataset. Download the dataset, extract the files\n",
    "and familiarize yourself with the data.\n",
    "\n",
    "There are 6 files available:\n",
    "- aisles.csv - aisles of the store\n",
    "- departments.csv - departments of the store\n",
    "- order_products__prior.csv - details of prior orders (historical data), tells which items\n",
    "  (products) were bought together in one basket (transaction)\n",
    "- order_products__train.csv - details of train orders (last order for each customer)\n",
    "- orders.csv - orders of the customers\n",
    "- products.csv - products of the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f127b",
   "metadata": {},
   "source": [
    "### 1.1 Products and Transactions\n",
    "\n",
    "We are not going to use the whole information provided by the dataset. For now, we are interested in\n",
    "the list of products that customers bought in each transaction. Let's focus on the\n",
    "`order_products__prior.csv` (historical transactions data) and `products.csv` (for the names of the\n",
    "products) files.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    ">>> order_products_prior_df[order_products_prior_df[\"order_id\"] == 2]\n",
    "\n",
    "    order_id  product_id  add_to_cart_order  reordered\n",
    "59         7       34050                  1          0\n",
    "60         7       46802                  2          0\n",
    "```\n",
    "\n",
    "We can see that a customer bought both products (with id `34050` and `46802`) in one transaction. \n",
    "\n",
    "If we want to check the names of the products, we can use the `products.csv` file:\n",
    "\n",
    "```python\n",
    ">>> products_df[products_df[\"product_id\"].isin([34050, 46802])]\n",
    "\n",
    "       product_id      product_name  aisle_id  department_id\n",
    "34049       34050      Orange Juice        31              7\n",
    "46801       46802  Pineapple Chunks       116              1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Preprocess the dataset into a format that is appropriate for checking the co-occurrences of products\n",
    "in transactions. It is up to you to decide what that format should be in order to perform the\n",
    "computations efficiently. You will later need to answer questions such as \"What is the overall\n",
    "number of transactions?\", \"What is the number of transactions in which a specific product was\n",
    "bought?\", \"What is the number of transactions in which two specific products were bought?\", etc. You\n",
    "may start with the original data layout and then return to this step if needed. You can work on\n",
    "product IDs and use the `products.csv` file later to check the product names.\n",
    "\n",
    "---\n",
    "\n",
    "Find top 10 products that customers bought the most and least often.\n",
    "\n",
    "---\n",
    "\n",
    "<span style=\"color:gold\">Note:</span> The dataset may suggest that the \"in\" relationship between\n",
    "items and baskets corresponds to real-life \"part of\" relationship. This is true in this case:\n",
    "products (items) are purchased together in larger transactions (baskets). However, you should be\n",
    "aware that for association rule learning, the \"in\" relationship could be any arbitrary many-to-many\n",
    "relationship, even if it appears \"backwards\" compared to real life. See [Section 6.1.2\n",
    "(pdf)](http://infolab.stanford.edu/~ullman/mmds/ch6.pdf) for an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "187c5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98defd",
   "metadata": {},
   "source": [
    "## 2 Association Rules\n",
    "\n",
    "Association rules are rules that express the relationship between items in transactions. They are\n",
    "usually presentented in the form `A -> B`, where `A` and `B` are subsets of items, and `A -> B`\n",
    "means that if items from `A` are purchased, then items from `B` are also purchased. We will refer to\n",
    "`A` as the antecedent and `B` as the consequent of the rule. It is quite common to consider\n",
    "consequents as single items, as it is easier to interpret the rules. For example, if the client buys\n",
    "bread and milk, then what other item is likely to be purchased with them?\n",
    "\n",
    "Let's consider an association rule `A -> B`.There are several metrics that can be used to evaluate\n",
    "its quality.  The most common metrics are:\n",
    "- `support` - the ratio of transactions that contain items from both `A` and `B` to the total number\n",
    "  of transactions (alternatively, just the number of such transactions); we can interpret it as how\n",
    "  often the rule applies,\n",
    "- `confidence` - the ratio of transactions that contain both `A` and `B` to the number of\n",
    "  transactions that contain `A`; we can interpret it as the probability of purchasing `B` given that\n",
    "  `A` was purchased,\n",
    "- `coverage` - the ratio of transactions that contain items from `A` to the total number of\n",
    "  transactions; we can interpret it as how often is `A` purchased; it informs us about the general\n",
    "  popularity of items from `A` in transactions and what is the fraction of transactions that the\n",
    "  rule is under consideration (no matter if `B` is purchased or not).\n",
    "  \n",
    "<span style=\"color:gold\">Note:</span> The concept of coverage can be defined not only\n",
    "for rules but also for itemsets. It is the ratio of transactions that contain the items from the\n",
    "itemset to the total number of transactions.\n",
    "\n",
    "---\n",
    "\n",
    "Write functions that let you compute support, confidence, and coverage metrics for association\n",
    "rules.\n",
    "\n",
    "Below, the product names are used for simplicity, but you should adapt this to the format you\n",
    "decided on in the previous step. Use your functions to compute the support, confidence, and coverage\n",
    "metrics of the following association rules:\n",
    "- {Bread} -> {Milk}\n",
    "- {Milk} -> {Bread}\n",
    "- {Bread, Milk} -> {Butter}\n",
    "- {Banana, Apple} -> {Milk}\n",
    "- {Bread, Milk, Butter} -> {Eggs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa48f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{33120, 17794, 40141, 9327, 30035, 43668, 2898...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{17668, 24838, 17704, 46667, 21903, 17461, 326...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{26434, 32645, 10054, 21351, 22598, 39758, 348...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{48002, 45698, 18569, 37011, 15005, 8479, 9633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{15873, 41897, 40462}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421079</th>\n",
       "      <td>{30136}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421080</th>\n",
       "      <td>{25122, 4932, 31717, 27845, 12935, 10667, 3806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421081</th>\n",
       "      <td>{38185, 32299, 3060, 35221, 12218, 20539, 12861}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421082</th>\n",
       "      <td>{12738, 47941, 12023, 43352, 32700, 16797, 17279}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421083</th>\n",
       "      <td>{18176, 4600, 21162, 35211, 7854, 24852, 11352...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214874 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 product_id\n",
       "order_id                                                   \n",
       "2         {33120, 17794, 40141, 9327, 30035, 43668, 2898...\n",
       "3         {17668, 24838, 17704, 46667, 21903, 17461, 326...\n",
       "4         {26434, 32645, 10054, 21351, 22598, 39758, 348...\n",
       "5         {48002, 45698, 18569, 37011, 15005, 8479, 9633...\n",
       "6                                     {15873, 41897, 40462}\n",
       "...                                                     ...\n",
       "3421079                                             {30136}\n",
       "3421080   {25122, 4932, 31717, 27845, 12935, 10667, 3806...\n",
       "3421081    {38185, 32299, 3060, 35221, 12218, 20539, 12861}\n",
       "3421082   {12738, 47941, 12023, 43352, 32700, 16797, 17279}\n",
       "3421083   {18176, 4600, 21162, 35211, 7854, 24852, 11352...\n",
       "\n",
       "[3214874 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "df = pd.read_csv(\"../../data/lab-11/order_products__prior.csv\")\n",
    "products_df = pd.read_csv(\"../../data/lab-11/products.csv\")\n",
    "aisles_df = pd.read_csv(\"../../data/lab-11/aisles.csv\")\n",
    "departments_df = pd.read_csv(\"../../data/lab-11/departments.csv\")\n",
    "\n",
    "# te = TransactionEncoder()\n",
    "# te_ary = te.fit(q[\"product_id\"]).transform(q[\"product_id\"])\n",
    "# w = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "q = df.groupby('order_id').agg({'product_id': lambda x: set(x)})\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "718a1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082\n",
      "20\n",
      "0.018484288354898338\n",
      "Organic European Style Lightly Salted Butter\n",
      "Vanilla Bean Ice Cream\n"
     ]
    }
   ],
   "source": [
    "PRODUCT_COL = \"product_id\"\n",
    "\n",
    "def cov_itemset(df, itemset: set[int], absolute=False, col=PRODUCT_COL):\n",
    "    count = df[col].map(lambda basket: itemset.issubset(basket)).sum()\n",
    "    return count if absolute else count / len(df)\n",
    "\n",
    "def coverage(df, rule, absolute=False, col=PRODUCT_COL):\n",
    "    antecedent, _ = rule\n",
    "    return cov_itemset(df, antecedent, absolute, col)\n",
    "\n",
    "def support(df, rule, absolute=False, col=PRODUCT_COL):\n",
    "    antecedent, consequent = rule\n",
    "    return cov_itemset(df, antecedent | consequent, absolute, col)\n",
    "\n",
    "def confidence(df, rule, col=PRODUCT_COL):\n",
    "    antecedent, consequent = rule\n",
    "    return cov_itemset(df, antecedent | consequent, absolute=True, col=col) / cov_itemset(df, antecedent, absolute=True, col=col)\n",
    "\n",
    "def show_product_name(products_df, product_id):\n",
    "    return products_df[products_df[\"product_id\"] == product_id][\"product_name\"].iloc[0]\n",
    "\n",
    "print(coverage(q, ({25122}, {4932}), absolute=True))\n",
    "print(support(q, ({25122}, {4932}), absolute=True))\n",
    "print(confidence(q, ({25122}, {4932})))\n",
    "\n",
    "print(show_product_name(products_df, 25122))\n",
    "print(show_product_name(products_df, 4932))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7b8ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chocolate Sandwich Cookies'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df[products_df[\"product_id\"] == 1][\"product_name\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b642fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = set([1, 2])\n",
    "s2 = set([2, 3])\n",
    "\n",
    "s1.issubset(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062138a2",
   "metadata": {},
   "source": [
    "## 3. Apriori Algorithm\n",
    "\n",
    "Before we start with the details on how to efficiently search for association rules, let's first\n",
    "state that the number of possible association rules is exponential in the number of items. We can\n",
    "choose any item as the consequent and any subset of the items as the antecedent. However, most of\n",
    "these association rules are not interesting and have no practical value. What we usually want to\n",
    "find (at least in the most basic cases) are association rules that have large enough support and\n",
    "confidence.\n",
    "\n",
    "To find an useful association rule is not much different from finding an interesting/frequent\n",
    "itemset. It is said that for brick-and-mortar stores, the reasonable threshold could be around 1%\n",
    "of the transactions. For online stores, where the number of products is much larger, the threshold\n",
    "is usually even lower ~0.1%.\n",
    "\n",
    "Suppose we have identified all \"interesting\" itemsets. We can then generate interesting association\n",
    "rules (meeting some additional criteria, such as \"high\" confidence) from them. The procedure to\n",
    "generate association rules from a frequent itemset `A` can be as simple as follows:\n",
    "- `A` consists of `n` items,\n",
    "- we have `n` possible association rules of the form $A \\setminus \\{a\\} \\rightarrow \\{a\\}$ for each\n",
    "  item $a \\in A$,\n",
    "- we check the confidence of each rule and keep only the ones that meet the confidence threshold.\n",
    "\n",
    "In practice, we strive to obtain not too many frequent itemsets and association rules. The computed\n",
    "results are usually presented to or interpreted by a human. Each additional association rule\n",
    "candidate needs some action to be taken. It is quite normal to modify the thresholds for support\n",
    "and confidence to modify the number of association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cc999",
   "metadata": {},
   "source": [
    "### 3.1 Frequent Itemsets\n",
    "\n",
    "Frequent itemsets are the sets of items that appear together in a transaction with a frequency\n",
    "higher than a given threshold. In other words, we are interested in itemsets with \"high\" (that\n",
    "depends on the context) coverage.\n",
    "\n",
    "**Property**: If `A` is a frequent itemset, then all subsets of `A` are frequent itemsets.\n",
    "\n",
    "Can you prove this property?\n",
    "\n",
    "---\n",
    "\n",
    "Below, the product names are used for simplicity, but you should adapt this to the format you\n",
    "decided on in the previous step. Compute the frequency of the following itemsets:\n",
    "- {Bread}\n",
    "- {Milk}\n",
    "- {Banana}\n",
    "- {Bread, Milk}\n",
    "- {Bread, Butter}\n",
    "- {Bread, Milk, Butter, Banana}\n",
    "\n",
    "How would you choose a reasonable frequency threshold to use? How would you approach this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a60aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a56c44",
   "metadata": {},
   "source": [
    "### 3.2 Searching for Frequent Itemsets\n",
    "\n",
    "As a consequence of the above property, if we detect an itemset that is not frequent, then we know\n",
    "that all its supersets are not frequent either. That observation is the basis of the Apriori\n",
    "algorithm.\n",
    "\n",
    "Apriori algorithm is an iterative algorithm that searches for frequent itemsets in a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1729556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c005f",
   "metadata": {},
   "source": [
    "### 3.3 Association Rules Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76711e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
