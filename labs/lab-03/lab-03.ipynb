{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61d579f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab 03 - Similarity Search in Large Datasets - Locality-Sensitive Hashing (LSH) with Random Projection\n",
    "\n",
    "During this lab we will study the concept of Similarity Search in large datasets. In particular, we\n",
    "will implement a simple version of Locality-Sensitive Hashing (LSH) using Random Projection.\n",
    "\n",
    "LSH is a popular technique for approximate nearest neighbor search in hight-dimensional spaces. The\n",
    "main idea behind it is to hash the input items in such a way that similar items are mapped to the\n",
    "same buckets. \n",
    "\n",
    "This approach differs from traditional hashing techniques, which aim to minimize collisions between\n",
    "different items. Here, we want to maximize the probability of collision for items that are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f6e36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1. The Dataset\n",
    "\n",
    "We will use one of the datasets employed to evaluate algorithms for approximate nearest neighbor\n",
    "search as part of [ANN Benchmarks](https://ann-benchmarks.com/) initiative. \n",
    "\n",
    "Please download one of the GloVe variants from the above link. Alternatively, you can download the\n",
    "dataset directly from the [GloVe](https://nlp.stanford.edu/projects/glove/) project page. Try to\n",
    "pick as large dataset version as possible to fully appreciate the benefits of LSH.\n",
    "\n",
    "See, Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for\n",
    "Word Representation [pdf](https://nlp.stanford.edu/pubs/glove.pdf) for more details about GloVe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a7f29d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "962819488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cec5439293c47398756c441acb0bf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "/home/sebov/synced/backup/workspace/dzd/data/lab-03/glove-200-angular.hdf5:   0%|          | 0.00/963M [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write your code here\n",
    "\n",
    "import pathlib\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "\n",
    "DATA_DIR = pathlib.Path.cwd().parent.parent / \"data\" / \"lab-03\"\n",
    "\n",
    "def download_file(url: str, dest: pathlib.Path) -> None:\n",
    "    \"\"\"Download file from url to dest path.\"\"\"\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    chunk_size = 8192\n",
    "\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        total_size = int(r.headers.get(\"content-length\", 0))\n",
    "        print(total_size)\n",
    "        r.raise_for_status()\n",
    "        with (\n",
    "            open(dest, \"wb\") as f,\n",
    "            tqdm(total=total_size, unit=\"B\", unit_scale=True, desc=str(dest)) as pbar,\n",
    "        ):\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "\n",
    "\n",
    "download_file(\n",
    "    \"http://ann-benchmarks.com/glove-200-angular.hdf5\",\n",
    "    DATA_DIR / \"glove-200-angular.hdf5\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "118f1c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1705239207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada1006035ca4ab3a85af9bfa5193cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "/home/sebov/synced/backup/workspace/dzd/data/lab-03/glove.2024.wikigiga.300d.zip:   0%|          | 0.00/1.71G …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_file(\n",
    "    \"https://nlp.stanford.edu/data/wordvecs/glove.2024.wikigiga.300d.zip\",\n",
    "    DATA_DIR / \"glove.2024.wikigiga.300d.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb555427",
   "metadata": {},
   "source": [
    "## 2. Investigate the Dataset\n",
    "\n",
    "What is the type of the dataset? What is the dimensionality? How many vectors does it contain?\n",
    "Can you fit the whole dataset in memory?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414fa4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1559b31",
   "metadata": {},
   "source": [
    "## 3. Similarity Search\n",
    "\n",
    "What is the preferred similarity metric for this dataset?\n",
    "\n",
    "What methods do you already know for performing similarity search? \n",
    "\n",
    "E.g., try brute-force, KD-Trees, Ball-Trees from `sklearn.neighbors` on a subset of the data. What\n",
    "is the subset size you can use to perform the computations in reasonable time? What are the\n",
    "complexities of these methods?\n",
    "\n",
    "You do not have to spend too much time on this section. Just get the feel of the problem and the\n",
    "main challenges associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dfdf37",
   "metadata": {},
   "source": [
    "## 4. Approximate Nearest Neighbors with LSH\n",
    "\n",
    "Sometimes, it is acceptable to retrieve approximate nearest neighbors instead of the exact ones. In\n",
    "many applications, we are absolutely fine with getting neighbors that are approximately close to\n",
    "the query point if we can get them much faster.\n",
    "\n",
    "What type of error can we observe when we retrieve approximate nearest neighbors? What are the\n",
    "interpretations of false positives and false negatives in this context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16278261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
